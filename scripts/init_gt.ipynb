{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import jax\n",
    "import json\n",
    "import pdal\n",
    "import laspy\n",
    "\n",
    "import whitebox\n",
    "import rasterio\n",
    "import traceback\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax.numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from jax import jit, vmap\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "from rasterio.transform import xy\n",
    "from rasterio.fill import fillnodata\n",
    "from multiprocessing import Process, Queue, Pool, cpu_count, get_context\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# whitebox.download_wbt(linux_musl=True, reset=True)\n",
    "\n",
    "wbt = whitebox.WhiteboxTools()\n",
    "wbt.verbose = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_lidar_dir = \"/mnt/data/sv_zh/merged_point_cloud\"\n",
    "ground_lidar_dir = \"/mnt/data/sv_zh/ground_lidar\"\n",
    "\n",
    "intensity_tif_dir = \"/mnt/data/sv_zh/intensity_tif\"\n",
    "elevation_tif_dir = \"/mnt/data/sv_zh/elevation_tif\"\n",
    "\n",
    "os.makedirs(ground_lidar_dir, exist_ok=True)\n",
    "os.makedirs(intensity_tif_dir, exist_ok=True)\n",
    "os.makedirs(elevation_tif_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Settings\n",
    "input_laz_folder = \"/mnt/data/sv_zh/point_cloud\"\n",
    "output_folder = \"/mnt/data/sv_zh/merged_point_cloud\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "gdf = gpd.read_file(\"/mnt/data/sv_zh/point_cloud.gpkg\")\n",
    "\n",
    "gdf[\"minx\"] = gdf.bounds.minx\n",
    "gdf[\"miny\"] = gdf.bounds.miny\n",
    "\n",
    "def snap_to_grid(x, y, size=200):\n",
    "    snapped_x = (x // size) * size\n",
    "    snapped_y = (y // size) * size\n",
    "    return snapped_x, snapped_y\n",
    "\n",
    "gdf[\"grid_x\"], gdf[\"grid_y\"] = zip(*gdf.apply(lambda row: snap_to_grid(row[\"minx\"], row[\"miny\"]), axis=1))\n",
    "\n",
    "groups = gdf.groupby([\"grid_x\", \"grid_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "for (grid_x, grid_y), group in tqdm(groups):\n",
    "    laz_files = group[\"filename\"].tolist()\n",
    "    laz_paths = [os.path.join(input_laz_folder, f) for f in laz_files]\n",
    "\n",
    "    output_filename = f\"merged_{grid_x}_{grid_y}.las\"\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "    # Build PDAL merge pipeline\n",
    "    inputs = [{\"filename\": path} for path in laz_paths]\n",
    "    pipeline = {\n",
    "        \"pipeline\": inputs + [{\"type\": \"writers.las\", \"filename\": output_path}]\n",
    "    }\n",
    "\n",
    "    # Write temporary JSON pipeline file\n",
    "    import json\n",
    "    temp_pipeline_path = \"temp_pipeline.json\"\n",
    "    with open(temp_pipeline_path, \"w\") as f:\n",
    "        json.dump(pipeline, f)\n",
    "\n",
    "    # Run the pipeline\n",
    "    subprocess.run([\"pdal\", \"pipeline\", temp_pipeline_path])\n",
    "\n",
    "    print(f\"Merged {len(laz_files)} tiles into {output_path}\")\n",
    "\n",
    "# Clean up temp file\n",
    "if os.path.exists(temp_pipeline_path):\n",
    "    os.remove(temp_pipeline_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Ground LiDAR (PDAL CSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 722/722 [02:17<00:00,  5.24it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline_template = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "        \"type\" : \"readers.las\",\n",
    "        \"filename\" : \"input.las\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[0:18]\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.csf\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[2:2]\"\n",
    "        },\n",
    "        {\n",
    "        \"type\" : \"writers.las\",\n",
    "        \"filename\" : \"output.las\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "laz_files = [f for f in os.listdir(raw_lidar_dir) if f.endswith('.laz')]\n",
    "\n",
    "for laz_file in tqdm(laz_files):\n",
    "    input_path = os.path.join(raw_lidar_dir, laz_file)\n",
    "    output_path = os.path.join(ground_lidar_dir, f\"ground_{laz_file.replace('.laz', '.las')}\")\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        continue\n",
    "    pipeline = pipeline_template\n",
    "    pipeline[\"pipeline\"][0]['filename'] = input_path\n",
    "    pipeline[\"pipeline\"][-1]['filename'] = output_path\n",
    "\n",
    "    pipeline_json = json.dumps(pipeline)\n",
    "    pipeline_obj = pdal.Pipeline(pipeline_json)\n",
    "    pipeline_obj.execute()\n",
    "\n",
    "    # print(f\"Processed: {laz_file} -> {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_template = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "        \"type\" : \"readers.las\",\n",
    "        \"filename\" : \"input.las\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[0:18]\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.csf\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[2:2]\"\n",
    "        },\n",
    "        {\n",
    "        \"type\" : \"writers.las\",\n",
    "        \"filename\" : \"output.las\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "laz_files = [f for f in os.listdir(raw_lidar_dir) if f.endswith('.laz')]\n",
    "\n",
    "def process_file(laz_file):\n",
    "    input_path = os.path.join(raw_lidar_dir, laz_file)\n",
    "    output_filename = f\"ground_{laz_file.replace('.laz', '.las')}\"\n",
    "    output_path = os.path.join(ground_lidar_dir, output_filename)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        return f\"Skipped: {laz_file}\"\n",
    "\n",
    "    pipeline = json.loads(json.dumps(pipeline_template))  # deep copy\n",
    "    pipeline[\"pipeline\"][0]['filename'] = input_path\n",
    "    pipeline[\"pipeline\"][-1]['filename'] = output_path\n",
    "\n",
    "    try:\n",
    "        pipeline_obj = pdal.Pipeline(json.dumps(pipeline))\n",
    "        pipeline_obj.execute()\n",
    "        return f\"Processed: {laz_file}\"\n",
    "    except RuntimeError as e:\n",
    "        return f\"Failed: {laz_file} with error {e}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap_unordered(process_file, laz_files), total=len(laz_files)))\n",
    "    \n",
    "    for res in results:\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_template = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "        \"type\" : \"readers.las\",\n",
    "        \"filename\" : \"input.las\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[0:18]\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.csf\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[2:2]\"\n",
    "        },\n",
    "        {\n",
    "        \"type\" : \"writers.las\",\n",
    "        \"filename\" : \"output.las\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "las_files = [f for f in os.listdir(raw_lidar_dir) if f.endswith('.las')]\n",
    "\n",
    "def process_file(las_file):\n",
    "    input_path = os.path.join(raw_lidar_dir, las_file)\n",
    "    output_filename = f\"ground_{las_file}\"\n",
    "    output_path = os.path.join(ground_lidar_dir, output_filename)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        return f\"Skipped: {las_file}\"\n",
    "\n",
    "    pipeline = json.loads(json.dumps(pipeline_template))  # deep copy\n",
    "    pipeline[\"pipeline\"][0]['filename'] = input_path\n",
    "    pipeline[\"pipeline\"][-1]['filename'] = output_path\n",
    "\n",
    "    try:\n",
    "        pipeline_obj = pdal.Pipeline(json.dumps(pipeline))\n",
    "        pipeline_obj.execute()\n",
    "        return f\"Processed: {las_file}\"\n",
    "    except RuntimeError as e:\n",
    "        return f\"Failed: {las_file} with error {e}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(processes=3) as pool:\n",
    "        results = list(tqdm(pool.imap_unordered(process_file, las_files), total=len(las_files)))\n",
    "    \n",
    "    for res in results:\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxel_density_filter(points, voxel_size=0.5):\n",
    "    \"\"\"Filter sparse points using voxel grid.\"\"\"\n",
    "    voxel_indices = np.floor(points / voxel_size).astype(np.int32)\n",
    "    dtype = [('x', np.int32), ('y', np.int32), ('z', np.int32)]\n",
    "    structured_voxels = np.core.records.fromarrays(voxel_indices.T, dtype=dtype)\n",
    "    _, inverse_indices, counts = np.unique(structured_voxels, return_inverse=True, return_counts=True)\n",
    "    min_points = np.quantile(counts, 0.3)\n",
    "    keep_mask = counts[inverse_indices] >= max(min_points, 150)\n",
    "    return keep_mask\n",
    "\n",
    "def remove_sparse(input_path, output_path):\n",
    "    \"\"\"Process a single LAS file.\"\"\"\n",
    "    las = laspy.read(input_path)\n",
    "    flag = voxel_density_filter(las.xyz, voxel_size=1.0)\n",
    "    dense_las = laspy.LasData(las.header)\n",
    "    dense_las.points = las.points[flag]\n",
    "    dense_las.write(output_path)\n",
    "\n",
    "def worker(task_queue, progress_queue):\n",
    "    \"\"\"Worker process: Computes but does no I/O.\"\"\"\n",
    "    while True:\n",
    "        task = task_queue.get()\n",
    "        if task is None:  # Sentinel to stop\n",
    "            break\n",
    "        input_path, output_path = task\n",
    "        try:\n",
    "            remove_sparse(input_path, output_path)\n",
    "            progress_queue.put(1)  # Update progress\n",
    "        except Exception as e:\n",
    "            print(f\"Failed processing {input_path}: {e}\")\n",
    "            progress_queue.put(0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = ground_lidar_dir\n",
    "    output_dir = ground_lidar_dir\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Prepare tasks (input/output paths)\n",
    "    ground_las = [f for f in os.listdir(input_dir) if f.startswith('ground_') and f.endswith('.las')]\n",
    "    tasks = []\n",
    "    for las_file in ground_las:\n",
    "        input_path = os.path.join(input_dir, las_file)\n",
    "        output_filename = f\"dense_{las_file.lstrip('ground_')}\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        if not os.path.exists(output_path):\n",
    "            tasks.append((input_path, output_path))\n",
    "\n",
    "    # Create queues\n",
    "    task_queue = Queue()\n",
    "    progress_queue = Queue()\n",
    "\n",
    "    # Start worker processes (4 workers)\n",
    "    num_workers = 8\n",
    "    workers = []\n",
    "    for _ in range(num_workers):\n",
    "        p = Process(target=worker, args=(task_queue, progress_queue))\n",
    "        p.start()\n",
    "        workers.append(p)\n",
    "\n",
    "    # Enqueue tasks (single producer)\n",
    "    for task in tasks:\n",
    "        task_queue.put(task)\n",
    "\n",
    "    # Add sentinels to stop workers\n",
    "    for _ in range(num_workers):\n",
    "        task_queue.put(None)\n",
    "\n",
    "    # Track progress with tqdm\n",
    "    progress = tqdm(total=len(tasks))\n",
    "    for _ in range(len(tasks)):\n",
    "        progress.update(progress_queue.get())  # Blocks until a worker reports progress\n",
    "    progress.close()\n",
    "\n",
    "    # Clean up\n",
    "    for p in workers:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def las_folder_to_bbox_gpkg(folder_path, output_gpkg):\n",
    "    polygons = []\n",
    "    filenames = []\n",
    "    num_pts = []\n",
    "\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        if filename.lower().endswith('.las') or filename.lower().endswith('.laz'):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            # Get bbox using pdal info\n",
    "            result = subprocess.run(['pdal', 'info', filepath], capture_output=True, text=True)\n",
    "            info = json.loads(result.stdout)\n",
    "            try:\n",
    "                bounds = info[\"stats\"]['bbox']['native']['bbox']\n",
    "                points = info[\"stats\"]['statistic'][0]['count']\n",
    "                num_pts.append(points)\n",
    "                \n",
    "                min_x, max_x = bounds['minx'], bounds['maxx']\n",
    "                min_y, max_y = bounds['miny'], bounds['maxy']\n",
    "                # We don't use Z here for 2D polygons\n",
    "\n",
    "                # Create a polygon from bbox corners\n",
    "                poly = Polygon([\n",
    "                    (min_x, min_y),\n",
    "                    (max_x, min_y),\n",
    "                    (max_x, max_y),\n",
    "                    (min_x, max_y),\n",
    "                    (min_x, min_y)  # Close the polygon\n",
    "                ])\n",
    "\n",
    "                polygons.append(poly)\n",
    "                filenames.append(filename)\n",
    "\n",
    "            except Exception:\n",
    "                num_pts.append(0)\n",
    "                polygons.append(None)\n",
    "                filenames.append(filename)\n",
    "\n",
    "    # Create a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame({'filename': filenames, 'num_pts': num_pts, 'geometry': polygons}, crs=\"EPSG:2056\")  # You can set your real CRS here!\n",
    "\n",
    "    # Save to GPKG\n",
    "    gdf.to_file(output_gpkg, driver=\"GPKG\")\n",
    "\n",
    "# Example usage:\n",
    "folder = '/mnt/data/sv_zh/point_cloud'\n",
    "output_gpkg = '/mnt/data/sv_zh/point_cloud.gpkg'\n",
    "las_folder_to_bbox_gpkg(folder, output_gpkg)\n",
    "\n",
    "print(\"✅ Saved bounding boxes to GPKG successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_files = [f for f in os.listdir(ground_lidar_dir) if f.startswith('ground_') and f.endswith('.las')]\n",
    "\n",
    "for las_file in tqdm(las_files):\n",
    "    input_path = os.path.join(ground_lidar_dir, las_file)\n",
    "    elevation_raster = os.path.join(elevation_tif_dir, f\"elevation_{las_file.lstrip('ground_').replace('.las', '.tif')}\")\n",
    "    intensity_raster = os.path.join(intensity_tif_dir, f\"intensity_{las_file.lstrip('ground_').replace('.las', '.tif')}\")\n",
    "\n",
    "    if not os.path.exists(intensity_raster):\n",
    "        wbt.lidar_idw_interpolation(\n",
    "            input_path,\n",
    "            intensity_raster,\n",
    "            parameter=\"intensity\",\n",
    "            returns=\"first\",\n",
    "            resolution=0.02,\n",
    "            radius=0.1,\n",
    "            weight=2.0\n",
    "        )\n",
    "\n",
    "    if not os.path.exists(elevation_raster):\n",
    "        wbt.lidar_idw_interpolation(\n",
    "            input_path,\n",
    "            elevation_raster,\n",
    "            parameter=\"elevation\",\n",
    "            returns=\"first\",\n",
    "            resolution=0.02,\n",
    "            radius=0.1,\n",
    "            weight=2.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_files = [f for f in os.listdir(ground_lidar_dir) if f.startswith('ground_') and f.endswith('.las')]\n",
    "\n",
    "def process_las_file(las_file):\n",
    "    input_path = os.path.join(ground_lidar_dir, las_file)\n",
    "    elevation_raster = os.path.join(elevation_tif_dir, f\"elevation_{las_file.lstrip('ground_').replace('.las', '.tif')}\")\n",
    "    intensity_raster = os.path.join(intensity_tif_dir, f\"intensity_{las_file.lstrip('ground_').replace('.las', '.tif')}\")\n",
    "\n",
    "    if not os.path.exists(intensity_raster):\n",
    "        wbt.lidar_idw_interpolation(\n",
    "            input_path,\n",
    "            intensity_raster,\n",
    "            parameter=\"intensity\",\n",
    "            returns=\"first\",\n",
    "            resolution=0.02,\n",
    "            radius=0.1,\n",
    "            weight=2.0\n",
    "        )\n",
    "\n",
    "\n",
    "    if not os.path.exists(elevation_raster):\n",
    "        wbt.lidar_idw_interpolation(\n",
    "            input_path,\n",
    "            elevation_raster,\n",
    "            parameter=\"elevation\",\n",
    "            returns=\"first\",\n",
    "            resolution=0.02,\n",
    "            radius=0.1,\n",
    "            weight=2.0\n",
    "        )\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=4) as pool:\n",
    "    results = list(tqdm(pool.imap_unordered(process_las_file, las_files), total=len(las_files)))\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data/sv_zh/ground_lidar'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_lidar_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbt.set_working_dir(ground_lidar_dir)\n",
    "wbt.lidar_idw_interpolation(\n",
    "    output=intensity_tif_dir,\n",
    "    parameter=\"intensity\",\n",
    "    returns=\"first\",\n",
    "    resolution=0.02,\n",
    "    radius=0.1,\n",
    "    weight=2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D GT (Circle detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img, nodata_value):\n",
    "    \"\"\"\n",
    "    Preprocess the image for Hough Circle detection.\n",
    "    Args:\n",
    "        img: Input image (2D NumPy array).\n",
    "        nodata_value: Value representing no data in the image.\n",
    "    Returns:\n",
    "        Preprocessed image (2D NumPy array).\n",
    "    \"\"\"\n",
    "    img[img == nodata_value] = np.median(img[img>=0])\n",
    "    img = np.clip(img, 25000, 45000)\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    img = img.astype(np.uint8)\n",
    "    img = denoise_tv_chambolle(img, weight=0.2, channel_axis=None) * 255\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(64,64))\n",
    "    img = clahe.apply(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def preprocess(img):\n",
    "    \"\"\"\n",
    "    Preprocess the image for Hough Circle detection with contrast enhancement using quantile clipping.\n",
    "    Args:\n",
    "        img: Input image (2D NumPy array).\n",
    "        nodata_value: Value representing no data in the image.\n",
    "        low_q: Lower quantile for contrast clipping (default 2%).\n",
    "        high_q: Upper quantile for contrast clipping (default 98%).\n",
    "    Returns:\n",
    "        Preprocessed image (2D NumPy array).\n",
    "    \"\"\"\n",
    "    valid_mask = img >= 0\n",
    "    median_val = np.median(img[valid_mask])\n",
    "    img[~valid_mask] = median_val\n",
    "\n",
    "    # Compute quantiles and clip\n",
    "    img = np.clip(img, 0, 1200)\n",
    "\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "\n",
    "    # Normalize to 0–255 range\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # img = img.astype(np.uint8)\n",
    "    # img = denoise_tv_chambolle(img, weight=0.2, channel_axis=None) * 255\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(64, 64))\n",
    "    img = clahe.apply(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def is_circle_flat(points, epsilon=0.15):\n",
    "    \"\"\"\n",
    "    Fits a plane to 3D points and checks if the points lie approximately on that plane.\n",
    "    \n",
    "    Args:\n",
    "        points: (N, 3) array-like list of 3D points.\n",
    "        epsilon: Threshold for maximum allowed deviation from the plane.\n",
    "        \n",
    "    Returns:\n",
    "        is_flat (bool): True if all points lie within epsilon of the plane.\n",
    "        normal (np.ndarray): The normal vector of the fitted plane.\n",
    "        max_distance (float): Maximum distance from points to the plane.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if len(points) < 3:\n",
    "        return False\n",
    "    \n",
    "    points = np.asarray(points, dtype=np.float64)\n",
    "    centroid = points.mean(axis=0)\n",
    "    centered = points - centroid\n",
    "\n",
    "    # Check rank deficiency\n",
    "    if np.linalg.matrix_rank(centered) < 2:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Regularized SVD approach\n",
    "        _, _, vh = np.linalg.svd(centered + 1e-10*np.random.randn(*centered.shape), \n",
    "                                full_matrices=False)\n",
    "        normal = vh[-1]\n",
    "        \n",
    "        # Safe normalization\n",
    "        norm = np.linalg.norm(normal)\n",
    "        if norm < 1e-10:\n",
    "            return False, None\n",
    "        \n",
    "    except Exception:\n",
    "        # Final fallback to PCA if everything else fails\n",
    "\n",
    "        pca = PCA(n_components=3)\n",
    "        pca.fit(points)\n",
    "        normal = pca.components_[2]\n",
    "        norm = np.linalg.norm(normal)\n",
    "        if norm < 1e-10:\n",
    "            return False, None\n",
    "        print(f\"Using PCA for normal vector.\")\n",
    "\n",
    "    normal /= norm\n",
    "\n",
    "    # Compute distances to plane\n",
    "    distances = np.dot(centered, normal)\n",
    "    max_distance = np.abs(np.max(distances) - np.min(distances))\n",
    "\n",
    "    return int(max_distance < epsilon), max_distance\n",
    "\n",
    "\n",
    "def to_gdf(circles, transform, crs, elevation_raster):\n",
    "    \"\"\"\n",
    "    Converts detected circles in image coordinates to a GeoDataFrame with 3D polygons.\n",
    "\n",
    "    Parameters:\n",
    "    - circles: List of detected circles with each entry as [x_pix, y_pix, r_pix].\n",
    "    - transform: Affine transform of the raster.\n",
    "    - crs: Coordinate Reference System of the raster.\n",
    "    - elevation: 2D NumPy array representing the elevation raster.\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame with 3D circle polygons.\n",
    "    \"\"\"\n",
    "    geometries = []\n",
    "    data = []\n",
    "\n",
    "    with rasterio.open(elevation_raster) as src_elevation:\n",
    "        elevation = src_elevation.read(1)\n",
    "        elev_nodata = src_elevation.profile['nodata']\n",
    "\n",
    "    for x_pix, y_pix, r_pix in circles:\n",
    "        # Create a point and buffer it to get a circle polygon\n",
    "        # adding 2 pixels to the radius to fully cover the circle\n",
    "        r_pix = r_pix + 1\n",
    "        center_pix = Point(x_pix, y_pix)\n",
    "        circle_pix = center_pix.buffer(r_pix)\n",
    "\n",
    "        img_coords = np.array(circle_pix.exterior.coords).round().astype(int)\n",
    "        img_coords[:, 1] = np.clip(img_coords[:, 1], 0, elevation.shape[0] - 1)\n",
    "        img_coords[:, 0] = np.clip(img_coords[:, 0], 0, elevation.shape[1] - 1)\n",
    "        z_map = elevation[img_coords[:, 1], img_coords[:, 0]]\n",
    "\n",
    "\n",
    "        if sum(z_map == elev_nodata) > 0 and sum(z_map != elev_nodata) > 0:\n",
    "            # Replace nodata values with the median of the valid elevation values\n",
    "            z_map[z_map == elev_nodata] = np.median(z_map[z_map != elev_nodata])\n",
    "        \n",
    "        elif sum(z_map == elev_nodata) == len(z_map):\n",
    "            # If all values are nodata, skip this circle\n",
    "            print(f\"All elevation values are nodata for circle at ({x_pix}, {y_pix})\")\n",
    "            z_map = np.zeros_like(z_map)\n",
    "\n",
    "        # Calculate center coordinates in map space\n",
    "        x_center, y_center = xy(transform, y_pix, x_pix)\n",
    "\n",
    "        # Pixel size (assuming square pixels)\n",
    "        pixel_size = (transform.a + abs(transform.e)) / 2.0\n",
    "        r_map = r_pix * pixel_size\n",
    "\n",
    "        # Create a point and buffer it to get a circle polygon\n",
    "        center_point = Point(x_center, y_center)\n",
    "        circle_polygon = center_point.buffer(r_map)\n",
    "\n",
    "        # Convert to 3D polygon with Z elevation\n",
    "        coords_3d = [(x, y, z) for x, y, z in np.concatenate([np.array(circle_polygon.exterior.coords), z_map[:, None]], axis=1)]\n",
    "\n",
    "        try:\n",
    "            # Check if the circle is flat\n",
    "            is_flat, max_distance = is_circle_flat(coords_3d, epsilon=0.15)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking flatness: {e}\")\n",
    "            continue\n",
    "        \n",
    "        circle_polygon = Polygon(coords_3d)\n",
    "\n",
    "        # Append to lists\n",
    "        geometries.append(circle_polygon)\n",
    "        data.append({\n",
    "            'x_center': x_center,\n",
    "            'y_center': y_center,\n",
    "            'radius_pix': r_pix,\n",
    "            'radius_map': r_map,\n",
    "            'z_center': np.median(z_map),\n",
    "            'is_flat': is_flat,\n",
    "            'max_distance': max_distance\n",
    "        })\n",
    "\n",
    "    return gpd.GeoDataFrame(data, geometry=geometries, crs=crs)\n",
    "\n",
    "\n",
    "def save_empty_gpkg(output_path, crs=\"EPSG:2056\"):  # Using Swiss CRS as example\n",
    "    # Create empty GeoDataFrame with correct schema\n",
    "    empty_gdf = gpd.GeoDataFrame(columns=[\n",
    "        'x_center', \n",
    "        'y_center', \n",
    "        'radius_pix', \n",
    "        'radius_map', \n",
    "        'z_center', \n",
    "        'is_flat',\n",
    "        'max_distance',\n",
    "        'geometry'\n",
    "    ], crs=crs)\n",
    "    \n",
    "    # Save to file\n",
    "    empty_gdf.to_file(output_path, driver=\"GPKG\")\n",
    "\n",
    "\n",
    "def process_file(file_name):\n",
    "    \"\"\"\n",
    "    Process a single file to detect manholes and save results to a GeoPackage.\n",
    "    Args:\n",
    "        file_name: Name of the input intensity raster file.\n",
    "    Returns:\n",
    "        Number of detected manholes or None if no circles were found.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define directories\n",
    "    intensity_tif_dir = \"/mnt/data/sv_zh/intensity_tif\"\n",
    "    elevation_tif_dir = \"/mnt/data/sv_zh/elevation_tif\"\n",
    "    gpkg_dir = '/mnt/data/sv_zh/gpkg'\n",
    "\n",
    "    if os.path.exists(os.path.join(gpkg_dir, file_name.replace('.tif', '.gpkg'))):\n",
    "        return None  \n",
    "          \n",
    "    elevation_raster = os.path.join(elevation_tif_dir, file_name.replace('intensity', 'elevation'))\n",
    "    intensity_raster = os.path.join(intensity_tif_dir, file_name)\n",
    "\n",
    "    try:\n",
    "        # Load intensity first and immediately process/release\n",
    "        with rasterio.open(intensity_raster) as src_intensity:\n",
    "            intensity = src_intensity.read(1)\n",
    "            inten_nodata = src_intensity.profile['nodata']\n",
    "            transform = src_intensity.transform\n",
    "            crs = src_intensity.crs\n",
    "        \n",
    "        # Process and immediately clear intermediate arrays\n",
    "        intensity = preprocess(intensity)\n",
    "        processed_img = intensity.copy()\n",
    "        del intensity  # Explicitly free memory\n",
    "\n",
    "        circles = cv2.HoughCircles(\n",
    "            processed_img,\n",
    "            cv2.HOUGH_GRADIENT,\n",
    "            dp=1.0,\n",
    "            minDist=25,     # minimum distance between circle centers\n",
    "            param1=80,      # higher threshold for Canny edge detector\n",
    "            param2=20,      # accumulator threshold (lower is more sensitive)\n",
    "            minRadius=10,\n",
    "            maxRadius=25\n",
    "        )\n",
    "\n",
    "        if circles is not None:\n",
    "            # print(f'{len(detected_circles)} manholes detected in {file_name}')\n",
    "            gdf = to_gdf(circles[0], transform, crs, elevation_raster)\n",
    "            # return gdf\n",
    "            gdf.to_file(os.path.join(gpkg_dir, file_name.replace('.tif', '.gpkg')), driver=\"GPKG\")\n",
    "            return len(circles)\n",
    "        else:\n",
    "            # Create empty file when no circles found\n",
    "            output_path = os.path.join(gpkg_dir, file_name.replace('.tif', '.gpkg'))\n",
    "            print(f\"No circles found in {file_name}. Saving empty GeoPackage.\")\n",
    "            save_empty_gpkg(output_path, crs)\n",
    "            return None\n",
    "        \n",
    "    except MemoryError:\n",
    "        print(f\"Memory error processing {file_name}\")\n",
    "        return None\n",
    "    except cv2.error as e:\n",
    "        print(f\"OpenCV error in {file_name}: {e}\")\n",
    "        return None\n",
    "    except rasterio.errors.RasterioError as e:\n",
    "        print(f\"Rasterio error in {file_name}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in {file_name}: {traceback.format_exc()}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        # Clean up\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 19/58 [01:13<01:51,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No circles found in intensity_merged_2682600.0_1247600.0.tif. Saving empty GeoPackage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [03:12<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "intensity_tif_dir = \"/mnt/data/sv_zh/intensity_tif\"\n",
    "# file_list = [f for f in os.listdir(intensity_tif_dir) if f.startswith('intensity_NE_5_')]\n",
    "file_list = [f for f in os.listdir(intensity_tif_dir) if f.endswith('.tif')]\n",
    "\n",
    "with Pool(processes=4) as pool:\n",
    "    results = list(tqdm(pool.imap_unordered(process_file, file_list), total=len(file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: Type and subtype of field definition are not compatible. Resetting to OFSTNone\n"
     ]
    }
   ],
   "source": [
    "gpkg_dir = '/mnt/data/sv_zh/gpkg'\n",
    "file_name = 'zh_manholes_20.gpkg'\n",
    "cmd = f'ogrmerge.py -f GPKG -o ../{file_name} -single *.gpkg'\n",
    "\n",
    "# Change to the directory\n",
    "os.chdir(gpkg_dir)\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "gdf_gt = gpd.read_file(f'/mnt/data/sv_zh/{file_name}')\n",
    "gdf_gt = gdf_gt.set_crs(epsg=2056, allow_override=True)\n",
    "gdf_gt.to_file(f'/mnt/data/sv_zh/{file_name}', driver='GPKG')\n",
    "# Transform to EPSG:32632\n",
    "# gdf_transformed = gdf_gt.to_crs(epsg=32632)\n",
    "# # Replace 'transformed_file.gpkg' with your desired output file name\n",
    "# gdf_transformed.to_file('/mnt/data/sv_ne/ne_manholes_flat_25000_20_32632.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate OD GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import jax\n",
    "import json\n",
    "import pdal\n",
    "import laspy\n",
    "\n",
    "import whitebox\n",
    "import rasterio\n",
    "import traceback\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import geopandas as gpd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from jax import jit, vmap\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "from rasterio.transform import xy\n",
    "from rasterio.fill import fillnodata\n",
    "from multiprocessing import Process, Queue, Pool, cpu_count, get_context\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ypr2mat(yaw: float, pitch: float, roll: float) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Reproduce Metashape's ypr2mat behavior.\n",
    "    Args:\n",
    "        yaw (float): Rotation about Y-axis (degrees).\n",
    "        pitch (float): Rotation about X-axis (degrees).\n",
    "        roll (float): Rotation about Z-axis (degrees).\n",
    "    Returns:\n",
    "        jnp.ndarray: 3x3 rotation matrix.\n",
    "    \"\"\"\n",
    "    # Convert degrees to radians\n",
    "    yaw = -jnp.radians(yaw)\n",
    "    pitch = jnp.radians(pitch)\n",
    "    roll = jnp.radians(roll)\n",
    "\n",
    "    # Rotation matrices for each axis\n",
    "    R_x = jnp.array([\n",
    "        [1, 0, 0],\n",
    "        [0, jnp.cos(pitch), -jnp.sin(pitch)],\n",
    "        [0, jnp.sin(pitch), jnp.cos(pitch)]\n",
    "    ])\n",
    "\n",
    "    R_y = jnp.array([\n",
    "        [jnp.cos(roll), 0, jnp.sin(roll)],\n",
    "        [0, 1, 0],\n",
    "        [-jnp.sin(roll), 0, jnp.cos(roll)]\n",
    "    ])\n",
    "\n",
    "    R_z = jnp.array([\n",
    "        [jnp.cos(yaw), -jnp.sin(yaw), 0],\n",
    "        [jnp.sin(yaw), jnp.cos(yaw), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # Combine rotations: Yaw → Pitch → Roll\n",
    "    R = R_z @ R_x @ R_y \n",
    "    return R\n",
    "\n",
    "@jit\n",
    "def transform_to_camera_crs(x: jnp.ndarray, y: jnp.ndarray, z: jnp.ndarray, camera_meta: dict) -> Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Transforms points from local CRS to camera CRS.\n",
    "    \n",
    "    Args:\n",
    "        x, y, z: 1D arrays (JAX arrays, NumPy arrays, or Pandas Series) of \n",
    "                 the x, y, z coordinates of points in local CRS.\n",
    "        camera_pose: Dictionary containing the camera orientation:\n",
    "                     {'yaw': yaw, 'pitch': pitch, 'roll': roll}\n",
    "                     \n",
    "    Returns:\n",
    "        A Tuple of three 1D arrays (x', y', z') representing points in camera CRS.\n",
    "    \"\"\"\n",
    "\n",
    "    # Rotation \n",
    "    R = ypr2mat(camera_meta['yaw'], camera_meta['pitch'], camera_meta['roll'])  # Camera to local\n",
    "    R_bore = ypr2mat(0, -90, 0)  # Boresight to camera\n",
    "    # R_bore = ypr2mat(0.5, -90, - 0.3)  # Boresight to camera\n",
    "    # R_bore = ypr2mat(0.332734, -89.8243, 0)  # Boresight to camera\n",
    "    R = R @ R_bore.T @ jnp.diag(jnp.array([1, -1, -1]))\n",
    "     \n",
    "    # Define a function for transforming a single point\n",
    "    # from global coordinates to camera coordinates\n",
    "    def transform_point(px, py, pz):\n",
    "        global_point = jnp.array([px, py, pz])\n",
    "        transformed_point = R.T @ (global_point)\n",
    "        return transformed_point\n",
    "\n",
    "    # Vectorize the transformation function\n",
    "    transform_points = vmap(transform_point)\n",
    "\n",
    "    # Apply the transformation in parallel\n",
    "    transformed_points = transform_points(x, y, z)  # Shape: (N, 3)\n",
    "    \n",
    "    # Split the transformed points back into separate arrays\n",
    "    x_cam, y_cam, z_cam = transformed_points.T\n",
    "    \n",
    "    return x_cam, y_cam, z_cam\n",
    "\n",
    "@jit\n",
    "def spherical_projection(x: jnp.ndarray, y: jnp.ndarray, z: jnp.ndarray, w: int, h: int) -> Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Project 3D LiDAR points to 2D spherical coordinates.\n",
    "\n",
    "    Args:\n",
    "        x (jnp.ndarray): X coordinates of the points.\n",
    "        y (jnp.ndarray): Y coordinates of the points.\n",
    "        z (jnp.ndarray): Z coordinates of the points.\n",
    "        w (int): Width of the output image.\n",
    "        h (int): Height of the output image.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]: \n",
    "            u (jnp.ndarray): U coordinates in the image.\n",
    "            v (jnp.ndarray): V coordinates in the image.\n",
    "            r (jnp.ndarray): Depth distances of the points.\n",
    "    \"\"\"\n",
    "    # Map azimuth and elevation to image coordinates\n",
    "    f = w / (2 * jnp.pi) \n",
    "    u = 0.5 * w + f * jnp.arctan2(x, z)  \n",
    "    v = 0.5 * h + f * jnp.arctan2(y, jnp.sqrt(x**2 + z**2)) \n",
    "\n",
    "    return u, v\n",
    "\n",
    "def replace_zeros_with_nearest(z):\n",
    "    z = np.asarray(z)\n",
    "    non_zero_indices = np.where(z != 0)[0]\n",
    "\n",
    "    if len(non_zero_indices) == 0:\n",
    "        return z  # nothing to replace\n",
    "\n",
    "    result = z.copy()\n",
    "    for i in np.where(z == 0)[0]:\n",
    "        # Find the nearest non-zero index\n",
    "        nearest_index = non_zero_indices[np.argmin(np.abs(non_zero_indices - i))]\n",
    "        result[i] = z[nearest_index]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON Z ((2560778.546 1204397.79 432.849, 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON Z ((2560818.338 1204422.75 433.012, 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>POLYGON Z ((2560781.04 1204415.25 433.16, 2560...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON Z ((2560888.203 1204466.718 433.742, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2063</td>\n",
       "      <td>POLYGON Z ((2557971.008 1203983.64 534.931, 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2892</td>\n",
       "      <td>POLYGON Z ((2527886.832 1195469.928 926.811, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>2893</td>\n",
       "      <td>POLYGON Z ((2527881.852 1195469.449 926.789, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>2894</td>\n",
       "      <td>POLYGON Z ((2527871.733 1195469.496 926.76, 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>2830</td>\n",
       "      <td>POLYGON Z ((2529407.513 1195464.325 929.91, 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>2895</td>\n",
       "      <td>POLYGON Z ((2529409.993 1195464.726 929.88, 25...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1401 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           geometry\n",
       "0        4  POLYGON Z ((2560778.546 1204397.79 432.849, 25...\n",
       "1        3  POLYGON Z ((2560818.338 1204422.75 433.012, 25...\n",
       "2        8  POLYGON Z ((2560781.04 1204415.25 433.16, 2560...\n",
       "3        5  POLYGON Z ((2560888.203 1204466.718 433.742, 2...\n",
       "4     2063  POLYGON Z ((2557971.008 1203983.64 534.931, 25...\n",
       "...    ...                                                ...\n",
       "1396  2892  POLYGON Z ((2527886.832 1195469.928 926.811, 2...\n",
       "1397  2893  POLYGON Z ((2527881.852 1195469.449 926.789, 2...\n",
       "1398  2894  POLYGON Z ((2527871.733 1195469.496 926.76, 25...\n",
       "1399  2830  POLYGON Z ((2529407.513 1195464.325 929.91, 25...\n",
       "1400  2895  POLYGON Z ((2529409.993 1195464.726 929.88, 25...\n",
       "\n",
       "[1401 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_gt = gpd.read_file('/mnt/Data/StreetView/data/neuchatel/NE_GT_3D.gpkg', layer='ne_gt_3d')\n",
    "gdf_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_flag = []\n",
    "# for gt_idx, circle in gdf_gt.iterrows():\n",
    "#     # world_coords = np.array(circle.geometry.geoms[0].exterior.coords)\n",
    "#     world_coords = np.array(circle.geometry.exterior.coords)\n",
    "#     x, y, z = world_coords.T\n",
    "\n",
    "#     if (z == 0).any():\n",
    "#             # replace zero Z values with the nearest non-zero value in z vector\n",
    "#             nan_flag.append(gt_idx)\n",
    "\n",
    "# gdf_gt.iloc[nan_flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gt_idx, circle in gdf_gt.iterrows():\n",
    "#     # world_coords = np.array(circle.geometry.geoms[0].exterior.coords)\n",
    "#     world_coords = np.array(circle.geometry.exterior.coords)\n",
    "#     x, y, z = world_coords.T\n",
    "\n",
    "#     if (z == 0).all():\n",
    "#         # Skip if all Z coordinates are zero\n",
    "#         print(f\"Skipping GT {gt_idx} due to zero Z values.\")\n",
    "#     if (z == 0).any():\n",
    "#             # replace zero Z values with the nearest non-zero value in z vector\n",
    "#             z = replace_zeros_with_nearest(z)\n",
    "#     # update circle.geometry with the new z values\n",
    "#     new_coords = np.column_stack((x, y, z))\n",
    "#     new_polygon = Polygon(new_coords)\n",
    "#     gdf_gt.at[gt_idx, 'geometry'] = new_polygon\n",
    "# gdf_gt = gdf_gt.set_crs(epsg=2056, allow_override=True)\n",
    "# gdf_gt.to_file('/mnt/data/sv_ne/NE_GT_3D.gpkg', driver='GPKG', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>course</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.560767e+06</td>\n",
       "      <td>1.204712e+06</td>\n",
       "      <td>455.581098</td>\n",
       "      <td>105.895672</td>\n",
       "      <td>-7.131229</td>\n",
       "      <td>1.825059</td>\n",
       "      <td>20200408_105231_001931.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.560787e+06</td>\n",
       "      <td>1.204708e+06</td>\n",
       "      <td>454.220432</td>\n",
       "      <td>100.162288</td>\n",
       "      <td>-7.111336</td>\n",
       "      <td>0.608047</td>\n",
       "      <td>20200408_105231_001927.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.560616e+06</td>\n",
       "      <td>1.204657e+06</td>\n",
       "      <td>467.589898</td>\n",
       "      <td>44.622530</td>\n",
       "      <td>-7.111165</td>\n",
       "      <td>2.067972</td>\n",
       "      <td>20200408_105231_001967.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.560590e+06</td>\n",
       "      <td>1.204588e+06</td>\n",
       "      <td>471.643720</td>\n",
       "      <td>39.649812</td>\n",
       "      <td>-7.101109</td>\n",
       "      <td>-1.411226</td>\n",
       "      <td>20200408_105231_001982.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.560758e+06</td>\n",
       "      <td>1.204715e+06</td>\n",
       "      <td>456.224258</td>\n",
       "      <td>107.918263</td>\n",
       "      <td>-7.058721</td>\n",
       "      <td>1.091168</td>\n",
       "      <td>20200408_105231_001933.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2.560638e+06</td>\n",
       "      <td>1.204641e+06</td>\n",
       "      <td>467.074302</td>\n",
       "      <td>207.065909</td>\n",
       "      <td>2.643797</td>\n",
       "      <td>2.774642</td>\n",
       "      <td>20200408_105231_001858.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2.560646e+06</td>\n",
       "      <td>1.204659e+06</td>\n",
       "      <td>465.583884</td>\n",
       "      <td>198.606049</td>\n",
       "      <td>2.758709</td>\n",
       "      <td>2.897041</td>\n",
       "      <td>20200408_105231_001862.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2.560785e+06</td>\n",
       "      <td>1.204705e+06</td>\n",
       "      <td>454.382229</td>\n",
       "      <td>279.734773</td>\n",
       "      <td>2.799553</td>\n",
       "      <td>-0.137647</td>\n",
       "      <td>20200408_105231_001896.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2.560648e+06</td>\n",
       "      <td>1.204664e+06</td>\n",
       "      <td>465.184202</td>\n",
       "      <td>196.669942</td>\n",
       "      <td>2.826690</td>\n",
       "      <td>3.809456</td>\n",
       "      <td>20200408_105231_001863.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2.560644e+06</td>\n",
       "      <td>1.204655e+06</td>\n",
       "      <td>465.993169</td>\n",
       "      <td>201.601529</td>\n",
       "      <td>3.013647</td>\n",
       "      <td>2.793830</td>\n",
       "      <td>20200408_105231_001861.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                x             y           z      course     pitch      roll  \\\n",
       "0    2.560767e+06  1.204712e+06  455.581098  105.895672 -7.131229  1.825059   \n",
       "1    2.560787e+06  1.204708e+06  454.220432  100.162288 -7.111336  0.608047   \n",
       "2    2.560616e+06  1.204657e+06  467.589898   44.622530 -7.111165  2.067972   \n",
       "3    2.560590e+06  1.204588e+06  471.643720   39.649812 -7.101109 -1.411226   \n",
       "4    2.560758e+06  1.204715e+06  456.224258  107.918263 -7.058721  1.091168   \n",
       "..            ...           ...         ...         ...       ...       ...   \n",
       "133  2.560638e+06  1.204641e+06  467.074302  207.065909  2.643797  2.774642   \n",
       "134  2.560646e+06  1.204659e+06  465.583884  198.606049  2.758709  2.897041   \n",
       "135  2.560785e+06  1.204705e+06  454.382229  279.734773  2.799553 -0.137647   \n",
       "136  2.560648e+06  1.204664e+06  465.184202  196.669942  2.826690  3.809456   \n",
       "137  2.560644e+06  1.204655e+06  465.993169  201.601529  3.013647  2.793830   \n",
       "\n",
       "                           File  \n",
       "0    20200408_105231_001931.jpg  \n",
       "1    20200408_105231_001927.jpg  \n",
       "2    20200408_105231_001967.jpg  \n",
       "3    20200408_105231_001982.jpg  \n",
       "4    20200408_105231_001933.jpg  \n",
       "..                          ...  \n",
       "133  20200408_105231_001858.jpg  \n",
       "134  20200408_105231_001862.jpg  \n",
       "135  20200408_105231_001896.jpg  \n",
       "136  20200408_105231_001863.jpg  \n",
       "137  20200408_105231_001861.jpg  \n",
       "\n",
       "[138 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_df = pd.read_csv('/home/shanci/Downloads/export_steep_ypr.csv')  # Replace with your actual file\n",
    "# target_files = ['20200408_073125_003815.jpg', '20200408_073125_003816.jpg', '20200410_113822_000050.jpg', '20200408_073125_003817.jpg', '20200408_073125_003818.jpg']\n",
    "# camera_df = camera_df[[f in target_files for f in camera_df.File.values]]\n",
    "camera_df['File'] = camera_df['name'] + '.jpg'\n",
    "camera_df.drop(columns=['name'], inplace=True)\n",
    "camera_df.rename(columns={'E':'x', 'N': 'y', 'H':'z', 'y': 'course', 'p':'pitch', 'r': 'roll'}, inplace=True)\n",
    "camera_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load camera metadata into a DataFrame\n",
    "all_camera_df = pd.read_csv('/mnt/Data/ai3d/potree/pointclouds/streetview_ne/pano/coordinates.txt', sep='\\t')  # Replace with your actual file\n",
    "# camera_df = camera_df[(camera_df.x >= 2559490) & (camera_df.x <= 2559600) &\n",
    "#                       (camera_df.y >= 1203500) & (camera_df.y <= 1203650)]\n",
    "all_camera_df.set_index('File', inplace=True)\n",
    "camera_df = all_camera_df.loc[camera_df.File]\n",
    "camera_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>course</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200408_105231_001931.jpg</td>\n",
       "      <td>296001.0</td>\n",
       "      <td>2560767.431</td>\n",
       "      <td>1204712.362</td>\n",
       "      <td>455.557</td>\n",
       "      <td>106.043683</td>\n",
       "      <td>-7.172697</td>\n",
       "      <td>1.816100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200408_105231_001927.jpg</td>\n",
       "      <td>296000.0</td>\n",
       "      <td>2560787.027</td>\n",
       "      <td>1204708.213</td>\n",
       "      <td>454.218</td>\n",
       "      <td>100.318340</td>\n",
       "      <td>-7.172395</td>\n",
       "      <td>0.586676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200408_105231_001967.jpg</td>\n",
       "      <td>296019.0</td>\n",
       "      <td>2560616.239</td>\n",
       "      <td>1204656.888</td>\n",
       "      <td>467.622</td>\n",
       "      <td>44.778868</td>\n",
       "      <td>-7.179832</td>\n",
       "      <td>2.049722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200408_105231_001982.jpg</td>\n",
       "      <td>296028.0</td>\n",
       "      <td>2560590.139</td>\n",
       "      <td>1204588.442</td>\n",
       "      <td>471.724</td>\n",
       "      <td>39.811514</td>\n",
       "      <td>-7.166640</td>\n",
       "      <td>-1.433506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200408_105231_001933.jpg</td>\n",
       "      <td>296002.0</td>\n",
       "      <td>2560757.768</td>\n",
       "      <td>1204715.091</td>\n",
       "      <td>456.216</td>\n",
       "      <td>108.060589</td>\n",
       "      <td>-7.117750</td>\n",
       "      <td>1.105352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>20200408_105231_001858.jpg</td>\n",
       "      <td>295916.0</td>\n",
       "      <td>2560638.284</td>\n",
       "      <td>1204640.920</td>\n",
       "      <td>467.044</td>\n",
       "      <td>207.215954</td>\n",
       "      <td>2.518321</td>\n",
       "      <td>2.774931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>20200408_105231_001862.jpg</td>\n",
       "      <td>295919.0</td>\n",
       "      <td>2560646.091</td>\n",
       "      <td>1204659.378</td>\n",
       "      <td>465.553</td>\n",
       "      <td>198.755847</td>\n",
       "      <td>2.648801</td>\n",
       "      <td>2.909677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>20200408_105231_001896.jpg</td>\n",
       "      <td>295939.0</td>\n",
       "      <td>2560784.770</td>\n",
       "      <td>1204705.462</td>\n",
       "      <td>454.388</td>\n",
       "      <td>279.893321</td>\n",
       "      <td>2.670385</td>\n",
       "      <td>-0.124579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>20200408_105231_001863.jpg</td>\n",
       "      <td>295920.0</td>\n",
       "      <td>2560647.494</td>\n",
       "      <td>1204664.227</td>\n",
       "      <td>465.163</td>\n",
       "      <td>196.817409</td>\n",
       "      <td>2.712496</td>\n",
       "      <td>3.823511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>20200408_105231_001861.jpg</td>\n",
       "      <td>295918.0</td>\n",
       "      <td>2560644.428</td>\n",
       "      <td>1204654.649</td>\n",
       "      <td>465.964</td>\n",
       "      <td>201.749452</td>\n",
       "      <td>2.892750</td>\n",
       "      <td>2.800172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           File      Time            x            y        z  \\\n",
       "0    20200408_105231_001931.jpg  296001.0  2560767.431  1204712.362  455.557   \n",
       "1    20200408_105231_001927.jpg  296000.0  2560787.027  1204708.213  454.218   \n",
       "2    20200408_105231_001967.jpg  296019.0  2560616.239  1204656.888  467.622   \n",
       "3    20200408_105231_001982.jpg  296028.0  2560590.139  1204588.442  471.724   \n",
       "4    20200408_105231_001933.jpg  296002.0  2560757.768  1204715.091  456.216   \n",
       "..                          ...       ...          ...          ...      ...   \n",
       "133  20200408_105231_001858.jpg  295916.0  2560638.284  1204640.920  467.044   \n",
       "134  20200408_105231_001862.jpg  295919.0  2560646.091  1204659.378  465.553   \n",
       "135  20200408_105231_001896.jpg  295939.0  2560784.770  1204705.462  454.388   \n",
       "136  20200408_105231_001863.jpg  295920.0  2560647.494  1204664.227  465.163   \n",
       "137  20200408_105231_001861.jpg  295918.0  2560644.428  1204654.649  465.964   \n",
       "\n",
       "         course     pitch      roll  \n",
       "0    106.043683 -7.172697  1.816100  \n",
       "1    100.318340 -7.172395  0.586676  \n",
       "2     44.778868 -7.179832  2.049722  \n",
       "3     39.811514 -7.166640 -1.433506  \n",
       "4    108.060589 -7.117750  1.105352  \n",
       "..          ...       ...       ...  \n",
       "133  207.215954  2.518321  2.774931  \n",
       "134  198.755847  2.648801  2.909677  \n",
       "135  279.893321  2.670385 -0.124579  \n",
       "136  196.817409  2.712496  3.823511  \n",
       "137  201.749452  2.892750  2.800172  \n",
       "\n",
       "[138 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "138it [00:02, 48.98it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "height, width = 4000, 8000\n",
    "image_info_ls = []\n",
    "annotations = []\n",
    "annotation_id = 1\n",
    "# Iterate over each camera\n",
    "for cam_idx, cam in tqdm(camera_df.iterrows()):\n",
    "    cam_point = Point(cam.x, cam.y)\n",
    "    cam_buffer = cam_point.buffer(20)  # 10-meter radius\n",
    "\n",
    "    # Filter circles within 20 meters\n",
    "    nearby_circles = gdf_gt[gdf_gt.geometry.centroid.within(cam_buffer)]\n",
    "    \n",
    "    # Proceed to project these circles to the image frame\n",
    "    if len(nearby_circles) == 0:\n",
    "        continue\n",
    "\n",
    "    for gt_idx, circle in nearby_circles.iterrows():\n",
    "        # world_coords = np.array(circle.geometry.geoms[0].exterior.coords)\n",
    "        world_coords = np.array(circle.geometry.exterior.coords)\n",
    "        x, y, z = world_coords.T\n",
    "\n",
    "        if (z == 0).all():\n",
    "            # Skip if all Z coordinates are zero\n",
    "            print(f\"Skipping GT {gt_idx} at camera {cam_idx} due to zero Z values.\")\n",
    "            continue\n",
    "        elif (z == 0).any():\n",
    "            # replace zero Z values with the nearest non-zero value in z vector\n",
    "            z[z == 0] = np.median(z[z != 0])\n",
    "\n",
    "        # shift coordinates center to gt  \n",
    "        x = jnp.array(x - cam.x)\n",
    "        y = jnp.array(y - cam.y)\n",
    "        z = jnp.array(z - cam.z)\n",
    "\n",
    "        cam_ori = {'yaw': cam.course + 0.5, 'pitch': cam.pitch + 0.0, 'roll': cam.roll - 0.3}\n",
    "        # cam_ori = {'yaw': cam.course, 'pitch': cam.pitch, 'roll': cam.roll}\n",
    "        # Transform points to camera CRS on GPU\n",
    "        cam_x, cam_y, cam_z = transform_to_camera_crs(x, y, z, cam_ori)\n",
    "            \n",
    "        u, v = vmap(spherical_projection, in_axes=(0, 0, 0, None, None))(cam_x, cam_y, cam_z, width, height)\n",
    "\n",
    "        # Handle wrapping around the image edges\n",
    "        if u.max() - u.min() > width / 2:\n",
    "            # If the range of u exceeds half the image width, keep the largest segment\n",
    "            u_right = jnp.where(u > width / 2, u , width-1)  # Wrap around\n",
    "            u_left = jnp.where(u < width / 2, u , 0)  # Wrap around\n",
    "            # compare the two segments and keep the one with the larger range\n",
    "            u = u_right if jnp.ptp(u_right) > jnp.ptp(u_left) else u_left\n",
    "\n",
    "        u = jnp.clip(u, 0, width - 1)  # Ensure u is within image bounds\n",
    "        i, j = u.astype(int), v.astype(int)\n",
    "        \n",
    "        # create a polygon with image coordinates and save to COCO format \n",
    "        # Create a polygon from the image coordinates\n",
    "        coords = np.array([i, j]).T\n",
    "        img_polygon = Polygon(coords)\n",
    "        # Calculate the area\n",
    "        area = img_polygon.area\n",
    "\n",
    "        # Retrieve the bounding box coordinates\n",
    "        minx, miny, maxx, maxy = img_polygon.bounds\n",
    "\n",
    "        # Compute width and height\n",
    "        w = maxx - minx\n",
    "        h = maxy - miny\n",
    "\n",
    "        if w >= 1000:\n",
    "            # Skip if the bounding box is too large\n",
    "            continue\n",
    "        # Format the bounding box for COCO: [x, y, width, height]\n",
    "        bbox = [float(minx), float(miny), float(w), float(h)]\n",
    "\n",
    "        # Append to annotations list    \n",
    "        annotations.append({\n",
    "            \"id\": annotation_id,\n",
    "            \"object_id\": gt_idx,\n",
    "            \"image_id\": cam_idx,\n",
    "            \"category_id\": 1,\n",
    "            \"segmentation\": [list(coords.flatten().astype('float'))],\n",
    "            \"area\": area,\n",
    "            \"bbox\": bbox,\n",
    "            \"iscrowd\": 0\n",
    "        })\n",
    "        annotation_id += 1\n",
    "\n",
    "    # Define image metadata\n",
    "    image_info_ls.append({\n",
    "        \"id\": cam_idx,\n",
    "        \"file_name\": cam.File,\n",
    "        \"width\": width,\n",
    "        \"height\": height\n",
    "    })\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"manhole\",\n",
    "        \"supercategory\": \"none\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Compile the final COCO structure\n",
    "coco_format = {\n",
    "    \"images\": image_info_ls,\n",
    "    \"annotations\": annotations,\n",
    "    \"categories\": categories\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"ne_steep_recalc_COCO.json\", \"w\") as json_file:\n",
    "    json.dump(coco_format, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Polygon as plt_Polygon\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = '20200408_073125_003877.jpg'  # Replace with your image path\n",
    "image = Image.open(image_path)\n",
    "\n",
    "\n",
    "polygon_coords = list(coords)\n",
    "# Convert to NumPy array for processing\n",
    "polygon_array = np.array(coords)\n",
    "\n",
    "# Calculate bounding box: (min_x, min_y, width, height)\n",
    "min_x = np.min(polygon_array[:, 0])\n",
    "min_y = np.min(polygon_array[:, 1])\n",
    "width = np.max(polygon_array[:, 0]) - min_x\n",
    "height = np.max(polygon_array[:, 1]) - min_y\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(image)\n",
    "# Create and add the polygon patch\n",
    "polygon_patch = plt_Polygon(polygon_coords, closed=True, edgecolor='blue', facecolor='blue', alpha=0.5)\n",
    "ax.add_patch(polygon_patch)\n",
    "# Create and add the bounding box patch\n",
    "bbox_patch = Rectangle((min_x, min_y), width, height, linewidth=2, edgecolor='red', facecolor='none')\n",
    "ax.add_patch(bbox_patch)\n",
    "\n",
    "# Optional: Add labels\n",
    "ax.text(min_x, min_y - 10, 'Polygon', color='blue', fontsize=12)\n",
    "ax.text(min_x, min_y - 25, 'Bounding Box', color='red', fontsize=12)\n",
    "\n",
    "# Set plot limits and show the plot\n",
    "ax.set_xlim(0, image.width)\n",
    "ax.set_ylim(image.height, 0)  # Invert y-axis to match image coordinates\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4472, 2676, 225, 109)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_x, min_y, width,height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Yaw (LV95): 235.212548°\n",
      "Grid Convergence Angle: 0.402166°\n"
     ]
    }
   ],
   "source": [
    "import pyproj\n",
    "import numpy as np\n",
    "\n",
    "def get_grid_convergence_angle(lon, lat, delta_lat=1e-5):\n",
    "    \"\"\"\n",
    "    Estimate grid convergence angle (true north - grid north) in degrees.\n",
    "    Positive if grid north is east of true north.\n",
    "    \"\"\"\n",
    "    transformer = pyproj.Transformer.from_crs(\"EPSG:4326\", \"EPSG:2056\", always_xy=True)\n",
    "    x1, y1 = transformer.transform(lon, lat)\n",
    "    x2, y2 = transformer.transform(lon, lat + delta_lat)\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    angle_rad = np.arctan2(dx, dy)\n",
    "    return np.rad2deg(angle_rad)\n",
    "\n",
    "def correct_yaw_for_lv95(yaw_true_north, lon, lat):\n",
    "    convergence = get_grid_convergence_angle(lon, lat)\n",
    "    yaw_lv95 = yaw_true_north - convergence\n",
    "    return yaw_lv95, convergence\n",
    "\n",
    "\n",
    "# WGS84 input: GPS + ENU orientation\n",
    "lon = 6.88926116691478       # Lausanne\n",
    "lat = 46.98733611884436\n",
    "height = 545.34600000000000    # meters above ellipsoid\n",
    "yaw = 235.61471396512013        # Facing East in ENU\n",
    "pitch = -2.37668345474374\n",
    "roll = 0.55190434543908\n",
    "\n",
    "\n",
    "\n",
    "yaw_lv95, convergence = correct_yaw_for_lv95(yaw, lon, lat)\n",
    "\n",
    "print(f\"Corrected Yaw (LV95): {yaw_lv95:.6f}°\")\n",
    "print(f\"Grid Convergence Angle: {convergence:.6f}°\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
